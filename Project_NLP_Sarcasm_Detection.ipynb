{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_NLP Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qpTpbnZmQ3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Activation, Flatten, Dense, Input, LSTM, Bidirectional, Dropout, Conv1D, MaxPool1D, CuDNNLSTM, GlobalMaxPool1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalMaxPool1D, GRU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbOyZS7NnR2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV4O6cOxnWN8",
        "colab_type": "code",
        "outputId": "d2fb01fd-0bf8-4ba0-8387-73b0928647af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMyHLGDxnX7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_path =\"/content/drive/My Drive/Data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYfzfPPoniao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df= pd.read_json('/content/gdrive/My Drive/Data/Sarcasm_Headlines_Dataset.json', lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK0uPOfMovKO",
        "colab_type": "code",
        "outputId": "731996a5-8267-4c59-e635-ea98ae2030a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pQdMLVDqKJ9",
        "colab_type": "code",
        "outputId": "bcb25676-98dc-4bf6-daa1-ba7882962e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = df[['headline','is_sarcastic']]\n",
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  former versace store clerk sues over secret 'b...             0\n",
              "1  the 'roseanne' revival catches up to our thorn...             0\n",
              "2  mom starting to fear son's web series closest ...             1\n",
              "3  boehner just wants wife to listen, not come up...             1\n",
              "4  j.k. rowling wishes snape happy birthday in th...             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY-DAHb8wGR5",
        "colab_type": "code",
        "outputId": "ecabfb3f-f2f6-44e1-89b7-17c428fb282a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(df.isnull().any(axis = 0)) #Checking for null values"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "headline        False\n",
            "is_sarcastic    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9mIHyPF96_w",
        "colab_type": "code",
        "outputId": "9e945287-3045-48a8-a15e-baf44beb6880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df[\"headline length\"]= df[\"headline\"].str.len() #Finding length of headline\n",
        "df"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26704</th>\n",
              "      <td>american politics in moral free-fall</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26705</th>\n",
              "      <td>america's best 20 hikes</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26706</th>\n",
              "      <td>reparations and obama</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26707</th>\n",
              "      <td>israeli ban targeting boycott supporters raise...</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26708</th>\n",
              "      <td>gourmet gifts for the foodie 2014</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26709 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                headline  ...  headline length\n",
              "0      former versace store clerk sues over secret 'b...  ...               78\n",
              "1      the 'roseanne' revival catches up to our thorn...  ...               84\n",
              "2      mom starting to fear son's web series closest ...  ...               79\n",
              "3      boehner just wants wife to listen, not come up...  ...               84\n",
              "4      j.k. rowling wishes snape happy birthday in th...  ...               64\n",
              "...                                                  ...  ...              ...\n",
              "26704               american politics in moral free-fall  ...               36\n",
              "26705                            america's best 20 hikes  ...               23\n",
              "26706                              reparations and obama  ...               21\n",
              "26707  israeli ban targeting boycott supporters raise...  ...               60\n",
              "26708                  gourmet gifts for the foodie 2014  ...               33\n",
              "\n",
              "[26709 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD7rw8LqvKDY",
        "colab_type": "code",
        "outputId": "8359df60-1b2d-4a68-cecb-57147c42822c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(df.is_sarcastic)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Sarcasm vs Non-sarcasm')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sarcasm vs Non-sarcasm')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCuj9UCt6hrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 85\n",
        "embedding_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STo3APH17o4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = Tokenizer(num_words = max_features)\n",
        "tok.fit_on_texts(df.headline)\n",
        "seqs = tok.texts_to_sequences(df.headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww4ozmI8wsx1",
        "colab_type": "code",
        "outputId": "a0640fee-d78c-4112-9b09-35b9eae1350d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "X = tok.texts_to_sequences(df['headline'])\n",
        "X = pad_sequences(X, maxlen = maxlen)\n",
        "Y = np.asarray(df['is_sarcastic'])\n",
        "\n",
        "print(\"Number of Samples:\", len(X))\n",
        "print(X[0])\n",
        "print(\"Number of Labels: \", len(Y))\n",
        "print(Y[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples: 26709\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0  307  678 3336 2297   47  381 2575    5 2576\n",
            " 8433]\n",
            "Number of Labels:  26709\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeh8FOF2zuvG",
        "colab_type": "code",
        "outputId": "aaa8bc04-1144-4d8c-d240-474c843a3316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.15, random_state = 10)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22702, 85) (22702,)\n",
            "(4007, 85) (4007,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uVco-UZ69D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_file = \"/content/gdrive/My Drive/Data/glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovChzC4e69cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract Glove embedding zip file\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(glove_file, 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3_wKRkn69z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = '/content/glove.6B.200d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssRvVgjd_lhW",
        "colab_type": "code",
        "outputId": "6d2f28fe-4c88-4ab7-8aec-3363dfd6c37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
        "\n",
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tok.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5BBzP4s7Cbx",
        "colab_type": "code",
        "outputId": "025e4de6-05f7-41dd-9373-41c7c0ab5201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "EMB_DIM = 6\n",
        "def fcmodel():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=max_features, output_dim= EMB_DIM, input_length=maxlen))    \n",
        "    \n",
        "    # Flatten Layer\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    # FC1\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # print model summary\n",
        "    model.summary()\n",
        "    \n",
        "    # When using pretrained embeddings\n",
        "    #model.layers[0].set_weights([embedding_matrix])\n",
        "    #model.layers[0].trainable = False\n",
        "              \n",
        "    # Compile the model\n",
        "    model.compile(optimizer = 'rmsprop',\n",
        "                 loss = 'binary_crossentropy',\n",
        "                 metrics = ['acc'])\n",
        "    return model\n",
        "\n",
        "fcmod = fcmodel()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 85, 6)             60000     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 510)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                32704     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 92,769\n",
            "Trainable params: 92,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQTp6U447DIQ",
        "colab_type": "code",
        "outputId": "ff1ee581-282e-4c0f-be80-8fd837219a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "fcmod.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=512, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = fcmod.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 22702 samples, validate on 4007 samples\n",
            "Epoch 1/10\n",
            " - 0s - loss: 0.1524 - acc: 0.9428 - val_loss: 0.3527 - val_acc: 0.8577\n",
            "Epoch 2/10\n",
            " - 0s - loss: 0.1415 - acc: 0.9478 - val_loss: 0.3579 - val_acc: 0.8615\n",
            "Epoch 3/10\n",
            " - 0s - loss: 0.1310 - acc: 0.9513 - val_loss: 0.3732 - val_acc: 0.8568\n",
            "Epoch 4/10\n",
            " - 0s - loss: 0.1213 - acc: 0.9555 - val_loss: 0.4092 - val_acc: 0.8428\n",
            "Epoch 5/10\n",
            " - 0s - loss: 0.1128 - acc: 0.9605 - val_loss: 0.3984 - val_acc: 0.8525\n",
            "Epoch 6/10\n",
            " - 0s - loss: 0.1037 - acc: 0.9629 - val_loss: 0.4165 - val_acc: 0.8468\n",
            "Epoch 7/10\n",
            " - 0s - loss: 0.0947 - acc: 0.9670 - val_loss: 0.4330 - val_acc: 0.8483\n",
            "Epoch 8/10\n",
            " - 0s - loss: 0.0857 - acc: 0.9697 - val_loss: 0.4551 - val_acc: 0.8470\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.0773 - acc: 0.9743 - val_loss: 0.4728 - val_acc: 0.8418\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.0685 - acc: 0.9774 - val_loss: 0.4880 - val_acc: 0.8403\n",
            "Accuracy: 84.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDifIt0DxYPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lstm model\n",
        "\n",
        "def lstmm():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim=max_features, output_dim=EMB_DIM, input_length=maxlen))\n",
        "    \n",
        "    model.add(Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.1, dropout=0.1)))\n",
        "    \n",
        "    model.add(Bidirectional(LSTM(32, recurrent_dropout=0.1, dropout=0.1)))\n",
        "    \n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer = 'rmsprop',\n",
        "                  loss = 'binary_crossentropy',\n",
        "                  metrics = ['acc'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "lsmod = lstmm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYRp0UI5xhZ3",
        "colab_type": "code",
        "outputId": "f662d808-e428-4827-a923-7902d47e9964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "lshist = lsmod.fit(X_train,Y_train,\n",
        "         epochs = 20,\n",
        "         batch_size = 512,\n",
        "         validation_data = (X_test, Y_test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 22702 samples, validate on 4007 samples\n",
            "Epoch 1/20\n",
            "22702/22702 [==============================] - 32s 1ms/step - loss: 0.6747 - acc: 0.5667 - val_loss: 0.6282 - val_acc: 0.7522\n",
            "Epoch 2/20\n",
            "22702/22702 [==============================] - 27s 1ms/step - loss: 0.4834 - acc: 0.7879 - val_loss: 0.3895 - val_acc: 0.8340\n",
            "Epoch 3/20\n",
            "22702/22702 [==============================] - 27s 1ms/step - loss: 0.3522 - acc: 0.8576 - val_loss: 0.3536 - val_acc: 0.8548\n",
            "Epoch 4/20\n",
            "22702/22702 [==============================] - 29s 1ms/step - loss: 0.2983 - acc: 0.8833 - val_loss: 0.3770 - val_acc: 0.8385\n",
            "Epoch 5/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.2577 - acc: 0.9007 - val_loss: 0.3239 - val_acc: 0.8610\n",
            "Epoch 6/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.2265 - acc: 0.9149 - val_loss: 0.3373 - val_acc: 0.8602\n",
            "Epoch 7/20\n",
            "22702/22702 [==============================] - 29s 1ms/step - loss: 0.2035 - acc: 0.9241 - val_loss: 0.3417 - val_acc: 0.8612\n",
            "Epoch 8/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.1848 - acc: 0.9320 - val_loss: 0.3633 - val_acc: 0.8585\n",
            "Epoch 9/20\n",
            "22702/22702 [==============================] - 27s 1ms/step - loss: 0.1705 - acc: 0.9396 - val_loss: 0.4196 - val_acc: 0.8458\n",
            "Epoch 10/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.1585 - acc: 0.9443 - val_loss: 0.3956 - val_acc: 0.8528\n",
            "Epoch 11/20\n",
            "22702/22702 [==============================] - 29s 1ms/step - loss: 0.1465 - acc: 0.9497 - val_loss: 0.4071 - val_acc: 0.8545\n",
            "Epoch 12/20\n",
            "22702/22702 [==============================] - 27s 1ms/step - loss: 0.1368 - acc: 0.9534 - val_loss: 0.4284 - val_acc: 0.8500\n",
            "Epoch 13/20\n",
            "22702/22702 [==============================] - 27s 1ms/step - loss: 0.1259 - acc: 0.9577 - val_loss: 0.4435 - val_acc: 0.8500\n",
            "Epoch 14/20\n",
            "22702/22702 [==============================] - 27s 1ms/step - loss: 0.1234 - acc: 0.9582 - val_loss: 0.4809 - val_acc: 0.8480\n",
            "Epoch 15/20\n",
            "22702/22702 [==============================] - 33s 1ms/step - loss: 0.1150 - acc: 0.9619 - val_loss: 0.4735 - val_acc: 0.8428\n",
            "Epoch 16/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.1069 - acc: 0.9668 - val_loss: 0.5128 - val_acc: 0.8420\n",
            "Epoch 17/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.1046 - acc: 0.9664 - val_loss: 0.5060 - val_acc: 0.8410\n",
            "Epoch 18/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.0956 - acc: 0.9708 - val_loss: 0.5325 - val_acc: 0.8413\n",
            "Epoch 19/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.0920 - acc: 0.9715 - val_loss: 0.5354 - val_acc: 0.8365\n",
            "Epoch 20/20\n",
            "22702/22702 [==============================] - 28s 1ms/step - loss: 0.0873 - acc: 0.9737 - val_loss: 0.5547 - val_acc: 0.8338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgUGUry5xm60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv1d():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim=max_features,output_dim=EMB_DIM, input_length=maxlen))\n",
        "    \n",
        "    model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
        "    \n",
        "    model.add(MaxPool1D(pool_size=5))\n",
        "    \n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "    \n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(GlobalMaxPool1D())\n",
        "    \n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics= ['acc'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "convmod = conv1d()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmI6_zKHxr1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "76a718c3-a492-4ffb-d8a9-055d9d4fd349"
      },
      "source": [
        "convhist = convmod.fit(X_train, Y_train,\n",
        "                      epochs = 20,\n",
        "                      batch_size = 512,\n",
        "                      validation_data = (X_test, Y_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 22702 samples, validate on 4007 samples\n",
            "Epoch 1/20\n",
            "22702/22702 [==============================] - 2s 98us/step - loss: 0.6785 - acc: 0.5551 - val_loss: 0.6535 - val_acc: 0.5698\n",
            "Epoch 2/20\n",
            "22702/22702 [==============================] - 2s 96us/step - loss: 0.5933 - acc: 0.6876 - val_loss: 0.5288 - val_acc: 0.7709\n",
            "Epoch 3/20\n",
            "22702/22702 [==============================] - 2s 86us/step - loss: 0.4560 - acc: 0.8098 - val_loss: 0.4422 - val_acc: 0.7891\n",
            "Epoch 4/20\n",
            "22702/22702 [==============================] - 2s 95us/step - loss: 0.3759 - acc: 0.8327 - val_loss: 0.4021 - val_acc: 0.8013\n",
            "Epoch 5/20\n",
            "22702/22702 [==============================] - 2s 89us/step - loss: 0.3317 - acc: 0.8507 - val_loss: 0.3919 - val_acc: 0.8101\n",
            "Epoch 6/20\n",
            "22702/22702 [==============================] - 2s 87us/step - loss: 0.3030 - acc: 0.8614 - val_loss: 0.3926 - val_acc: 0.8091\n",
            "Epoch 7/20\n",
            "22702/22702 [==============================] - 2s 98us/step - loss: 0.2805 - acc: 0.8709 - val_loss: 0.3997 - val_acc: 0.8073\n",
            "Epoch 8/20\n",
            "22702/22702 [==============================] - 2s 92us/step - loss: 0.2646 - acc: 0.8771 - val_loss: 0.4142 - val_acc: 0.8066\n",
            "Epoch 9/20\n",
            "22702/22702 [==============================] - 2s 98us/step - loss: 0.2497 - acc: 0.8833 - val_loss: 0.4219 - val_acc: 0.8031\n",
            "Epoch 10/20\n",
            "22702/22702 [==============================] - 2s 97us/step - loss: 0.2388 - acc: 0.8878 - val_loss: 0.4371 - val_acc: 0.7989\n",
            "Epoch 11/20\n",
            "22702/22702 [==============================] - 2s 91us/step - loss: 0.2271 - acc: 0.8935 - val_loss: 0.4585 - val_acc: 0.7934\n",
            "Epoch 12/20\n",
            "22702/22702 [==============================] - 2s 87us/step - loss: 0.2176 - acc: 0.8977 - val_loss: 0.4702 - val_acc: 0.7961\n",
            "Epoch 13/20\n",
            "22702/22702 [==============================] - 2s 87us/step - loss: 0.2092 - acc: 0.9023 - val_loss: 0.4927 - val_acc: 0.7961\n",
            "Epoch 14/20\n",
            "22702/22702 [==============================] - 2s 91us/step - loss: 0.2005 - acc: 0.9055 - val_loss: 0.5084 - val_acc: 0.7926\n",
            "Epoch 15/20\n",
            "22702/22702 [==============================] - 2s 94us/step - loss: 0.1940 - acc: 0.9089 - val_loss: 0.5195 - val_acc: 0.7894\n",
            "Epoch 16/20\n",
            "22702/22702 [==============================] - 2s 96us/step - loss: 0.1866 - acc: 0.9113 - val_loss: 0.5444 - val_acc: 0.7931\n",
            "Epoch 17/20\n",
            "22702/22702 [==============================] - 2s 87us/step - loss: 0.1790 - acc: 0.9146 - val_loss: 0.5655 - val_acc: 0.7891\n",
            "Epoch 18/20\n",
            "22702/22702 [==============================] - 2s 92us/step - loss: 0.1728 - acc: 0.9175 - val_loss: 0.5809 - val_acc: 0.7891\n",
            "Epoch 19/20\n",
            "22702/22702 [==============================] - 2s 94us/step - loss: 0.1673 - acc: 0.9199 - val_loss: 0.6037 - val_acc: 0.7889\n",
            "Epoch 20/20\n",
            "22702/22702 [==============================] - 2s 91us/step - loss: 0.1615 - acc: 0.9216 - val_loss: 0.6286 - val_acc: 0.7856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3-bBI457S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building and training Conv1D + GRU model\n",
        "\n",
        "def convgru():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim=max_features,output_dim=EMB_DIM, input_length=maxlen))\n",
        "    \n",
        "    model.add(Conv1D(filters=32, kernel_size=7, activation='relu'))\n",
        "    \n",
        "    model.add(MaxPool1D(pool_size=5))\n",
        "    \n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "    \n",
        "    model.add(GRU(32, dropout=0.1, recurrent_dropout=0.5))\n",
        "    \n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics= ['acc'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "convgrumod = convgru()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWW4fiFI5_wK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "fbd1f417-439c-4d3f-c8af-c9fff8a33273"
      },
      "source": [
        "convgruhist = convgrumod.fit(X_train, Y_train, \n",
        "                           epochs = 15,\n",
        "                           batch_size=512,\n",
        "                           validation_data = (X_test, Y_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 22702 samples, validate on 4007 samples\n",
            "Epoch 1/15\n",
            "22702/22702 [==============================] - 3s 144us/step - loss: 0.2073 - acc: 0.9034 - val_loss: 0.4775 - val_acc: 0.7929\n",
            "Epoch 2/15\n",
            "22702/22702 [==============================] - 3s 152us/step - loss: 0.1953 - acc: 0.9088 - val_loss: 0.5181 - val_acc: 0.7934\n",
            "Epoch 3/15\n",
            "22702/22702 [==============================] - 4s 157us/step - loss: 0.1850 - acc: 0.9140 - val_loss: 0.4962 - val_acc: 0.7954\n",
            "Epoch 4/15\n",
            "22702/22702 [==============================] - 4s 156us/step - loss: 0.1760 - acc: 0.9182 - val_loss: 0.5473 - val_acc: 0.7916\n",
            "Epoch 5/15\n",
            "22702/22702 [==============================] - 3s 154us/step - loss: 0.1670 - acc: 0.9207 - val_loss: 0.5452 - val_acc: 0.7924\n",
            "Epoch 6/15\n",
            "22702/22702 [==============================] - 3s 149us/step - loss: 0.1585 - acc: 0.9257 - val_loss: 0.5619 - val_acc: 0.7891\n",
            "Epoch 7/15\n",
            "22702/22702 [==============================] - 3s 146us/step - loss: 0.1498 - acc: 0.9288 - val_loss: 0.5963 - val_acc: 0.7874\n",
            "Epoch 8/15\n",
            "22702/22702 [==============================] - 3s 152us/step - loss: 0.1413 - acc: 0.9325 - val_loss: 0.6278 - val_acc: 0.7844\n",
            "Epoch 9/15\n",
            "22702/22702 [==============================] - 3s 148us/step - loss: 0.1351 - acc: 0.9342 - val_loss: 0.6537 - val_acc: 0.7806\n",
            "Epoch 10/15\n",
            "22702/22702 [==============================] - 3s 154us/step - loss: 0.1280 - acc: 0.9369 - val_loss: 0.7373 - val_acc: 0.7734\n",
            "Epoch 11/15\n",
            "22702/22702 [==============================] - 3s 140us/step - loss: 0.1216 - acc: 0.9398 - val_loss: 0.7213 - val_acc: 0.7796\n",
            "Epoch 12/15\n",
            "22702/22702 [==============================] - 3s 141us/step - loss: 0.1164 - acc: 0.9422 - val_loss: 0.7489 - val_acc: 0.7771\n",
            "Epoch 13/15\n",
            "22702/22702 [==============================] - 4s 155us/step - loss: 0.1129 - acc: 0.9435 - val_loss: 0.7905 - val_acc: 0.7764\n",
            "Epoch 14/15\n",
            "22702/22702 [==============================] - 3s 146us/step - loss: 0.1063 - acc: 0.9462 - val_loss: 0.7927 - val_acc: 0.7746\n",
            "Epoch 15/15\n",
            "22702/22702 [==============================] - 3s 147us/step - loss: 0.1022 - acc: 0.9460 - val_loss: 0.8205 - val_acc: 0.7739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ijeqfkh6QYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bb68e06-4dde-43de-ef47-98c1753a984a"
      },
      "source": [
        "instance = Y_test[5]\n",
        "print(instance)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGV4leu-y6lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shows it is a non-sarcastic comment"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}